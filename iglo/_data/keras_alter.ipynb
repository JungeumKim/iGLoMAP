{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F-MNIST\n",
    "ds = torchvision.datasets.FashionMNIST('/home/kim2712/Desktop/data',\n",
    "                                       train=True,\n",
    "                                       transform=torchvision.transforms.Compose([\n",
    "                                           torchvision.transforms.ToTensor()]))\n",
    "ds_tst = torchvision.datasets.FashionMNIST('/home/kim2712/Desktop/data',\n",
    "                                           train=False,\n",
    "                                           transform=torchvision.transforms.Compose([\n",
    "                                               torchvision.transforms.ToTensor()]))\n",
    "loader = DataLoader(ds, batch_size=60000, shuffle=False)\n",
    "loader_tst = DataLoader(ds, batch_size=10000, shuffle=False)\n",
    "\n",
    "for (x_train, y_train) in loader: break\n",
    "for (x_test, y_test) in loader_tst: break\n",
    "\n",
    "path = \"/home/kim2712/Desktop/data/FashionMNIST/JK_np\"\n",
    "for (name,array) in [(\"x_train\",x_train),(\"y_train\",y_train), (\"x_test\",x_test), (\"y_test\",y_test)]:\n",
    "    with open(path+\"/\"+name+'.npy', 'wb') as f:\n",
    "        np.save(f, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KMNIST\n",
    "ds = torchvision.datasets.KMNIST('/home/kim2712/Desktop/data',\n",
    "                                train=True,\n",
    "                                transform=torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor()]))\n",
    "ds_tst = torchvision.datasets.KMNIST('/home/kim2712/Desktop/data',\n",
    "                                    train=False,\n",
    "                                    transform=torchvision.transforms.Compose([\n",
    "                                        torchvision.transforms.ToTensor()]))\n",
    "loader = DataLoader(ds, batch_size=60000, shuffle=False)\n",
    "loader_tst = DataLoader(ds, batch_size=10000, shuffle=False)\n",
    "\n",
    "for (x_train, y_train) in loader: break\n",
    "for (x_test, y_test) in loader_tst: break\n",
    "\n",
    "path = \"/home/kim2712/Desktop/data/KMNIST/JK_np\"\n",
    "for (name,array) in [(\"x_train\",x_train),(\"y_train\",y_train), (\"x_test\",x_test), (\"y_test\",y_test)]:\n",
    "    with open(path+\"/\"+name+'.npy', 'wb') as f:\n",
    "        np.save(f, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CIFAR\n",
    "ds = torchvision.datasets.CIFAR10('/home/kim2712/Desktop/data',\n",
    "                                train=True,\n",
    "                                transform=torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor()]))\n",
    "ds_tst = torchvision.datasets.CIFAR10('/home/kim2712/Desktop/data',\n",
    "                                    train=False,\n",
    "                                    transform=torchvision.transforms.Compose([\n",
    "                                        torchvision.transforms.ToTensor()]))\n",
    "loader = DataLoader(ds, batch_size=60000, shuffle=False)\n",
    "loader_tst = DataLoader(ds, batch_size=10000, shuffle=False)\n",
    "\n",
    "for (x_train, y_train) in loader: break\n",
    "for (x_test, y_test) in loader_tst: break\n",
    "\n",
    "path = \"/home/kim2712/Desktop/data/CIFAR10/JK_np\"\n",
    "for (name,array) in [(\"x_train\",x_train),(\"y_train\",y_train), (\"x_test\",x_test), (\"y_test\",y_test)]:\n",
    "    with open(path+\"/\"+name+'.npy', 'wb') as f:\n",
    "        np.save(f, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MNIST\n",
    "ds = torchvision.datasets.MNIST('/home/kim2712/Desktop/data',\n",
    "                                train=True,\n",
    "                                transform=torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.ToTensor()]))\n",
    "ds_tst = torchvision.datasets.MNIST('/home/kim2712/Desktop/data',\n",
    "                                    train=False,\n",
    "                                    transform=torchvision.transforms.Compose([\n",
    "                                        torchvision.transforms.ToTensor()]))\n",
    "loader = DataLoader(ds, batch_size=60000, shuffle=False)\n",
    "loader_tst = DataLoader(ds, batch_size=10000, shuffle=False)\n",
    "\n",
    "for (x_train, y_train) in loader: break\n",
    "for (x_test, y_test) in loader_tst: break\n",
    "\n",
    "path = \"/home/kim2712/Desktop/data/MNIST/JK_np\"\n",
    "for (name,array) in [(\"x_train\",x_train),(\"y_train\",y_train), (\"x_test\",x_test), (\"y_test\",y_test)]:\n",
    "    with open(path+\"/\"+name+'.npy', 'wb') as f:\n",
    "        np.save(f, array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#luxury: \n",
    "import FlowCal\n",
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('flow18_for_optsne.csv', delimiter=',', skip_header=1)\n",
    "s = FlowCal.io.FCSData(\"flow18_annotated.fcs\")\n",
    "with open(\"./x_flow18.npy\", 'wb') as f: np.save(f, my_data)\n",
    "\n",
    "with open(\"./y_flow18.npy\", 'wb') as f: np.save(f, s[:,-1])\n",
    "\n",
    "\n",
    "my_data = genfromtxt('mass41_for_optsne.csv', delimiter=',', skip_header=1)\n",
    "s = FlowCal.io.FCSData(\"mass41_annotated.fcs\")\n",
    "\n",
    "with open(\"./x_mass41.npy\", 'wb') as f: np.save(f, my_data)\n",
    "    \n",
    "with open(\"./y_mass41.npy\", 'wb') as f: np.save(f, s[:,-1])\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My forA100_3 Kernel)",
   "language": "python",
   "name": "fora100_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
